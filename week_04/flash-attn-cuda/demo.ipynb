{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903b9ae4",
   "metadata": {},
   "source": [
    "# FlashAttention (Didactic CUDA) â€” Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39396e",
   "metadata": {},
   "source": [
    "Compile the CUDA program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec246739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -e\n",
    "nvcc -O3 -std=c++17 flash_attn_cuda.cu -o flash_attn_cuda\n",
    "./flash_attn_cuda 512 64 64 64 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9239456",
   "metadata": {},
   "source": [
    "Try a couple more sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "./flash_attn_cuda 768 64 64 64 7\n",
    "./flash_attn_cuda 1024 64 64 64 123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3ac43",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Increase `DMAX/BR/BC` at compile time if your GPU has room.\n",
    "- For `d > 128`, sub-tile over `d` to keep register pressure reasonable."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
