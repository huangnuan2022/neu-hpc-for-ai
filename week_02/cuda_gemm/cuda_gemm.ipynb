{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX3RwuT0gz0m",
        "outputId": "2d0abf82-077c-4b4b-f2f1-25d05fbb6aa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 23 21:38:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gemm.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <cstring>\n",
        "#include <cmath>\n",
        "#include <string>\n",
        "#include <iostream>\n",
        "\n",
        "#ifndef CHECK_CUDA\n",
        "#define CHECK_CUDA(call) do {                                      \\\n",
        "  cudaError_t _e = (call);                                         \\\n",
        "  if (_e != cudaSuccess) {                                         \\\n",
        "    fprintf(stderr, \"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__,  \\\n",
        "            cudaGetErrorString(_e));                               \\\n",
        "    std::exit(1);                                                  \\\n",
        "  }                                                                \\\n",
        "} while (0)\n",
        "#endif\n",
        "\n",
        "// Row-major indexing helpers\n",
        "__host__ __device__ inline int idxA(int r, int c, int K) { return r * K + c; }\n",
        "__host__ __device__ inline int idxB(int r, int c, int N) { return r * N + c; }\n",
        "__host__ __device__ inline int idxC(int r, int c, int N) { return r * N + c; }\n",
        "__host__ __device__ inline int idxD(int r, int c, int N) { return r * N + c; }\n",
        "\n",
        "// ------------------------- NAIVE KERNEL -------------------------\n",
        "__global__ void gemm_naive_kernel(const float* __restrict__ A,\n",
        "                                  const float* __restrict__ B,\n",
        "                                  const float* __restrict__ C,\n",
        "                                  float* __restrict__ D,\n",
        "                                  int M, int N, int K,\n",
        "                                  float alpha, float beta) {\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y; // [0, M)\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x; // [0, N)\n",
        "\n",
        "  if (row >= M || col >= N) return;\n",
        "\n",
        "  float acc = 0.0f;\n",
        "  for (int k = 0; k < K; ++k) {\n",
        "    acc = fmaf(A[idxA(row, k, K)], B[idxB(k, col, N)], acc); // A[row,k]*B[k,col] + acc\n",
        "  }\n",
        "  D[idxD(row, col, N)] = alpha * acc + beta * C[idxC(row, col, N)];\n",
        "}\n",
        "\n",
        "// --------------------- TILED/SHARED-MEM KERNEL ------------------\n",
        "// Each thread computes 1 output element. Tiles are BLOCK x BLOCK.\n",
        "// We pad shared tiles by +1 on the second dim to reduce bank conflicts.\n",
        "template<int BLOCK>\n",
        "__global__ void gemm_tiled_kernel(const float* __restrict__ A,\n",
        "                                  const float* __restrict__ B,\n",
        "                                  const float* __restrict__ C,\n",
        "                                  float* __restrict__ D,\n",
        "                                  int M, int N, int K,\n",
        "                                  float alpha, float beta) {\n",
        "  __shared__ float As[BLOCK][BLOCK + 1];\n",
        "  __shared__ float Bs[BLOCK][BLOCK + 1];\n",
        "\n",
        "  int row = blockIdx.y * BLOCK + threadIdx.y;\n",
        "  int col = blockIdx.x * BLOCK + threadIdx.x;\n",
        "\n",
        "  float acc = 0.0f;\n",
        "  const int tiles = (K + BLOCK - 1) / BLOCK;\n",
        "\n",
        "  for (int t = 0; t < tiles; ++t) {\n",
        "    int aCol = t * BLOCK + threadIdx.x;\n",
        "    int bRow = t * BLOCK + threadIdx.y;\n",
        "\n",
        "    // Load tiles into shared memory (guarded)\n",
        "    As[threadIdx.y][threadIdx.x] =\n",
        "        (row < M && aCol < K) ? A[idxA(row, aCol, K)] : 0.0f;\n",
        "    Bs[threadIdx.y][threadIdx.x] =\n",
        "        (bRow < K && col < N) ? B[idxB(bRow, col, N)] : 0.0f;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int k = 0; k < BLOCK; ++k) {\n",
        "      acc = fmaf(As[threadIdx.y][k], Bs[k][threadIdx.x], acc);\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  if (row < M && col < N) {\n",
        "    D[idxD(row, col, N)] = alpha * acc + beta * C[idxC(row, col, N)];\n",
        "  }\n",
        "}\n",
        "\n",
        "// --------------------------- CPU REF ----------------------------\n",
        "void cpu_gemm(const std::vector<float>& A,\n",
        "              const std::vector<float>& B,\n",
        "              const std::vector<float>& C,\n",
        "              std::vector<float>& D,\n",
        "              int M, int N, int K,\n",
        "              float alpha, float beta) {\n",
        "  for (int i = 0; i < M; ++i) {\n",
        "    for (int j = 0; j < N; ++j) {\n",
        "      double acc = 0.0;\n",
        "      for (int k = 0; k < K; ++k) {\n",
        "        acc += static_cast<double>(A[idxA(i,k,K)]) * static_cast<double>(B[idxB(k,j,N)]);\n",
        "      }\n",
        "      D[idxD(i,j,N)] = static_cast<float>(alpha * acc + beta * C[idxC(i,j,N)]);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// --------------------------- UTILS ------------------------------\n",
        "float max_abs_diff(const std::vector<float>& X, const std::vector<float>& Y) {\n",
        "  float m = 0.0f;\n",
        "  for (size_t i = 0; i < X.size(); ++i) {\n",
        "    m = fmaxf(m, fabsf(X[i] - Y[i]));\n",
        "  }\n",
        "  return m;\n",
        "}\n",
        "\n",
        "double gflops_gemm(long long M, long long N, long long K, double ms) {\n",
        "  // GEMM does ~2*M*N*K MACs (+ 2*M*N for axpby on C), count all as FLOPs\n",
        "  double flops = 2.0 * M * N * K + 2.0 * M * N;\n",
        "  return flops / (ms * 1e6); // GFLOP/s\n",
        "}\n",
        "\n",
        "struct Args {\n",
        "  int M=1024, N=1024, K=1024;\n",
        "  int repeat=20;\n",
        "  float alpha=1.0f, beta=1.0f;\n",
        "  std::string kernel=\"tiled\"; // \"naive\" or \"tiled\"\n",
        "  int block=32;               // tile size for tiled kernel\n",
        "  int seed=42;\n",
        "};\n",
        "\n",
        "Args parse_args(int argc, char** argv) {\n",
        "  Args a;\n",
        "  for (int i=1; i<argc; ++i) {\n",
        "    std::string s(argv[i]);\n",
        "    auto next = [&](int &i){ return std::string(argv[++i]); };\n",
        "    if (s==\"--m\") a.M = std::stoi(next(i));\n",
        "    else if (s==\"--n\") a.N = std::stoi(next(i));\n",
        "    else if (s==\"--k\") a.K = std::stoi(next(i));\n",
        "    else if (s==\"--alpha\") a.alpha = std::stof(next(i));\n",
        "    else if (s==\"--beta\") a.beta = std::stof(next(i));\n",
        "    else if (s==\"--repeat\") a.repeat = std::stoi(next(i));\n",
        "    else if (s==\"--kernel\") a.kernel = next(i);\n",
        "    else if (s==\"--block\") a.block = std::stoi(next(i));\n",
        "    else if (s==\"--seed\") a.seed = std::stoi(next(i));\n",
        "    else if (s==\"-h\" || s==\"--help\") {\n",
        "      printf(\"Usage: ./gemm [--m M] [--n N] [--k K] [--alpha A] [--beta B] \"\n",
        "             \"[--repeat R] [--kernel naive|tiled] [--block 16|32] [--seed S]\\n\");\n",
        "      std::exit(0);\n",
        "    }\n",
        "  }\n",
        "  return a;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "  Args args = parse_args(argc, argv);\n",
        "  int M = args.M, N = args.N, K = args.K;\n",
        "  float alpha = args.alpha, beta = args.beta;\n",
        "\n",
        "  // Host buffers\n",
        "  std::vector<float> A(M*K), B(K*N), C(M*N), D(M*N), D_ref(M*N);\n",
        "\n",
        "  // Init random\n",
        "  std::mt19937 rng(args.seed);\n",
        "  std::uniform_real_distribution<float> dist(-1.0f, 1.0f);\n",
        "  for (auto &x : A) x = dist(rng);\n",
        "  for (auto &x : B) x = dist(rng);\n",
        "  for (auto &x : C) x = dist(rng);\n",
        "\n",
        "  // Device buffers\n",
        "  float *dA=nullptr, *dB=nullptr, *dC=nullptr, *dD=nullptr;\n",
        "  CHECK_CUDA(cudaMalloc(&dA, sizeof(float)*A.size()));\n",
        "  CHECK_CUDA(cudaMalloc(&dB, sizeof(float)*B.size()));\n",
        "  CHECK_CUDA(cudaMalloc(&dC, sizeof(float)*C.size()));\n",
        "  CHECK_CUDA(cudaMalloc(&dD, sizeof(float)*D.size()));\n",
        "  CHECK_CUDA(cudaMemcpy(dA, A.data(), sizeof(float)*A.size(), cudaMemcpyHostToDevice));\n",
        "  CHECK_CUDA(cudaMemcpy(dB, B.data(), sizeof(float)*B.size(), cudaMemcpyHostToDevice));\n",
        "  CHECK_CUDA(cudaMemcpy(dC, C.data(), sizeof(float)*C.size(), cudaMemcpyHostToDevice));\n",
        "\n",
        "  // Launch params\n",
        "  dim3 block(16,16);\n",
        "  dim3 grid((N + block.x - 1)/block.x, (M + block.y - 1)/block.y);\n",
        "\n",
        "  // Warmup + timing\n",
        "  cudaEvent_t start, stop;\n",
        "  CHECK_CUDA(cudaEventCreate(&start));\n",
        "  CHECK_CUDA(cudaEventCreate(&stop));\n",
        "\n",
        "  // Select kernel\n",
        "  auto run_naive = [&](){\n",
        "    gemm_naive_kernel<<<grid, block>>>(dA, dB, dC, dD, M, N, K, alpha, beta);\n",
        "  };\n",
        "\n",
        "  auto run_tiled = [&](){\n",
        "    if (args.block == 16) {\n",
        "      dim3 b(16,16), g((N+15)/16,(M+15)/16);\n",
        "      gemm_tiled_kernel<16><<<g, b>>>(dA,dB,dC,dD,M,N,K,alpha,beta);\n",
        "    } else { // default 32\n",
        "      dim3 b(32,32), g((N+31)/32,(M+31)/32);\n",
        "      gemm_tiled_kernel<32><<<g, b>>>(dA,dB,dC,dD,M,N,K,alpha,beta);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  // Warmup\n",
        "  if (args.kernel == \"naive\") run_naive(); else run_tiled();\n",
        "  CHECK_CUDA(cudaDeviceSynchronize());\n",
        "\n",
        "  // Time\n",
        "  CHECK_CUDA(cudaEventRecord(start));\n",
        "  for (int i=0;i<args.repeat;++i) {\n",
        "    if (args.kernel == \"naive\") run_naive(); else run_tiled();\n",
        "  }\n",
        "  CHECK_CUDA(cudaEventRecord(stop));\n",
        "  CHECK_CUDA(cudaEventSynchronize(stop));\n",
        "  float ms=0.0f;\n",
        "  CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));\n",
        "  ms /= args.repeat;\n",
        "\n",
        "  // Copy back\n",
        "  CHECK_CUDA(cudaMemcpy(D.data(), dD, sizeof(float)*D.size(), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  // CPU reference (smaller shapes are fast; for big shapes this is still okay but slower)\n",
        "  cpu_gemm(A,B,C,D_ref,M,N,K,alpha,beta);\n",
        "\n",
        "  // Check max abs diff\n",
        "  float mad = max_abs_diff(D, D_ref);\n",
        "\n",
        "  // Report\n",
        "  double gflops = gflops_gemm(M,N,K, ms);\n",
        "  std::cout << \"Kernel = \" << args.kernel\n",
        "            << \"  M=\" << M << \" N=\" << N << \" K=\" << K\n",
        "            << \"  alpha=\" << alpha << \" beta=\" << beta << \"\\n\";\n",
        "  std::cout << \"Avg time: \" << ms << \" ms   Throughput: \"\n",
        "            << gflops << \" GFLOP/s\\n\";\n",
        "  std::cout << \"Max |GPU-CPU|: \" << mad << \"\\n\";\n",
        "\n",
        "  // Cleanup\n",
        "  CHECK_CUDA(cudaFree(dA));\n",
        "  CHECK_CUDA(cudaFree(dB));\n",
        "  CHECK_CUDA(cudaFree(dC));\n",
        "  CHECK_CUDA(cudaFree(dD));\n",
        "  CHECK_CUDA(cudaEventDestroy(start));\n",
        "  CHECK_CUDA(cudaEventDestroy(stop));\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou0adZg6g01P",
        "outputId": "6a71de40-2cb0-4816-c6e9-b3be53de4fbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gemm.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 gemm.cu -o gemm"
      ],
      "metadata": {
        "id": "DM6HCUQog8p9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NaÃ¯ve kernel (correct but slower)\n",
        "!./gemm --m 512 --n 512 --k 512 --alpha 1.25 --beta 0.75 --kernel naive --repeat 50\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZCd2_jng-Im",
        "outputId": "1d21311b-d24e-4edf-f9ba-b02fc5c8bd97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel = naive  M=512 N=512 K=512  alpha=1.25 beta=0.75\n",
            "Avg time: 0.0002752 ms   Throughput: 977325 GFLOP/s\n",
            "Max |GPU-CPU|: 43.7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiled/shared-memory kernel (faster)\n",
        "!./gemm --m 1024 --n 1024 --k 1024 --alpha 1.0 --beta 1.0 --kernel tiled --block 32 --repeat 30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzYZeiEQhCQu",
        "outputId": "1ced983d-e513-47dc-e374-4fd27ff62b33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel = tiled  M=1024 N=1024 K=1024  alpha=1 beta=1\n",
            "Avg time: 0.000349867 ms   Throughput: 6.144e+06 GFLOP/s\n",
            "Max |GPU-CPU|: 51.3591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xia6fKCuhEcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}