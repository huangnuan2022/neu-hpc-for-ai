{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia"
    },
    "language_info": {
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import Downloads\n",
        "import Base.Filesystem: filesize\n",
        "using Pkg\n",
        "Pkg.add(\"CUDA\")\n",
        "using CUDA\n",
        "using Test\n",
        "\n",
        "macro bash_str(s) open(`bash`,\"w\",stdout) do io; print(io, s); end; end\n",
        "const CKPT_URL = \"https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin\"\n",
        "const CKPT_PATH = \"stories15M.bin\"\n",
        "\n",
        "Downloads.download(CKPT_URL, CKPT_PATH)\n",
        "println(\"File size bytes = \", filesize(CKPT_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVUR0pcht3QT",
        "outputId": "2cb059f5-7895-42f1-9241-ccbfe5e2c396"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size bytes = 60816028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "struct Config\n",
        "    dim::Int32\n",
        "    hidden_dim::Int32\n",
        "    n_layers::Int32\n",
        "    n_heads::Int32\n",
        "    n_kv_heads::Int32\n",
        "    vocab_size::Int32\n",
        "    seq_len::Int32\n",
        "end\n",
        "\n",
        "struct TensorF32\n",
        "    data::Vector{Float32}\n",
        "    dims::Vector{Int}  # dynamic shape for simplicity\n",
        "end\n",
        "TensorF32(n_elems::Int, dims::Vector{Int}) = ( @assert prod(dims)==n_elems; TensorF32(Vector{Float32}(undef, n_elems), dims) )\n",
        "to_array(t::TensorF32) = reshape(t.data, Tuple(t.dims))\n",
        "\n",
        "mutable struct TransformerWeights\n",
        "    token_embedding_table::TensorF32  # (V, d)\n",
        "    rms_att_weight::TensorF32         # (L, d)\n",
        "    wq::TensorF32                     # (L, d, d)\n",
        "    wk::TensorF32                     # (L, d, d)\n",
        "    wv::TensorF32                     # (L, d, d)\n",
        "    wo::TensorF32                     # (L, d, d)\n",
        "    rms_ffn_weight::TensorF32         # (L, d)\n",
        "    w1::TensorF32                     # (L, hd, d)\n",
        "    w2::TensorF32                     # (L, d,  hd)\n",
        "    w3::TensorF32                     # (L, hd, d)\n",
        "    rms_final_weight::TensorF32       # (d,)\n",
        "    freq_cis_real::TensorF32          # (T, HS/2)\n",
        "    freq_cis_imag::TensorF32          # (T, HS/2)\n",
        "end\n",
        "\n",
        "\n",
        "read_i32(io) = read(io, Int32)\n",
        "\n",
        "function read_tensor!(io, dims::Vector{Int})\n",
        "    t = TensorF32(prod(dims), dims)\n",
        "    read!(io, t.data)  # read Float32 stream into buffer\n",
        "    return t\n",
        "end\n",
        "\n",
        "\n",
        "const HEADER_ORDER = [1,2,3,4,5,6,7]\n",
        "\n",
        "function read_header(io)\n",
        "    raw7 = [Int(read_i32(io)) for _ in 1:7]  # Vector{Int} length 7\n",
        "    vals = raw7[HEADER_ORDER]                 # same order, explicit vector indexing\n",
        "    dim, hidden_dim, n_layers, n_heads, n_kv_heads, vocab_size, seq_len = vals\n",
        "    # sanity\n",
        "    @assert all(>(0), vals)\n",
        "    @assert n_kv_heads <= n_heads\n",
        "    @assert dim % n_heads == 0\n",
        "    head_size = dim ÷ n_heads\n",
        "    @assert head_size % 2 == 0\n",
        "    return Config(Int32(dim), Int32(hidden_dim), Int32(n_layers), Int32(n_heads),\n",
        "                  Int32(n_kv_heads), Int32(vocab_size), Int32(seq_len))\n",
        "end\n",
        "\n",
        "\n",
        "function read_checkpoint(path::AbstractString)\n",
        "    open(path, \"r\") do io\n",
        "        cfg = read_header(io)\n",
        "\n",
        "        d  = Int(cfg.dim)\n",
        "        hd = Int(cfg.hidden_dim)\n",
        "        L  = Int(cfg.n_layers)\n",
        "        H  = Int(cfg.n_heads)\n",
        "        V  = Int(cfg.vocab_size)\n",
        "        T  = Int(cfg.seq_len)\n",
        "        @assert d % H == 0\n",
        "        HS  = d ÷ H\n",
        "        @assert HS % 2 == 0\n",
        "        HS2 = HS ÷ 2\n",
        "\n",
        "        token_embedding_table = read_tensor!(io, [V, d])\n",
        "        rms_att_weight        = read_tensor!(io, [L, d])\n",
        "        wq                    = read_tensor!(io, [L, d, d])\n",
        "        wk                    = read_tensor!(io, [L, d, d])\n",
        "        wv                    = read_tensor!(io, [L, d, d])\n",
        "        wo                    = read_tensor!(io, [L, d, d])\n",
        "        rms_ffn_weight        = read_tensor!(io, [L, d])\n",
        "        w1                    = read_tensor!(io, [L, hd, d])\n",
        "        w2                    = read_tensor!(io, [L, d,  hd])\n",
        "        w3                    = read_tensor!(io, [L, hd, d])\n",
        "        rms_final_weight      = read_tensor!(io, [d])\n",
        "        freq_cis_real         = read_tensor!(io, [T, HS2])\n",
        "        freq_cis_imag         = read_tensor!(io, [T, HS2])\n",
        "\n",
        "        weights = TransformerWeights(\n",
        "            token_embedding_table, rms_att_weight,\n",
        "            wq, wk, wv, wo, rms_ffn_weight, w1, w2, w3,\n",
        "            rms_final_weight, freq_cis_real, freq_cis_imag\n",
        "        )\n",
        "        return cfg, weights, position(io)\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "function expected_f32_count(cfg::Config)\n",
        "    d  = Int(cfg.dim)\n",
        "    hd = Int(cfg.hidden_dim)\n",
        "    L  = Int(cfg.n_layers)\n",
        "    H  = Int(cfg.n_heads)\n",
        "    V  = Int(cfg.vocab_size)\n",
        "    T  = Int(cfg.seq_len)\n",
        "    HS  = d ÷ H\n",
        "    HS2 = HS ÷ 2\n",
        "    emb      = V*d\n",
        "    rms_att  = L*d\n",
        "    four_mm  = 4 * (L*d*d)  # wq,wk,wv,wo\n",
        "    rms_ffn  = L*d\n",
        "    w1sz     = L*hd*d\n",
        "    w2sz     = L*d*hd\n",
        "    w3sz     = L*hd*d\n",
        "    rmsfin   = d\n",
        "    cis      = 2 * (T*HS2)  # real + imag\n",
        "    return emb + rms_att + four_mm + rms_ffn + w1sz + w2sz + w3sz + rmsfin + cis\n",
        "end\n",
        "\n",
        "function run_selftests(path::AbstractString)\n",
        "    cfg, w, bytes_consumed = read_checkpoint(path)\n",
        "\n",
        "\n",
        "    @assert cfg.dim > 0\n",
        "    @assert cfg.hidden_dim > 0\n",
        "    @assert cfg.n_layers > 0\n",
        "    @assert cfg.n_heads > 0\n",
        "    @assert cfg.n_kv_heads > 0 && cfg.n_kv_heads <= cfg.n_heads\n",
        "    @assert cfg.vocab_size >= 1000\n",
        "    @assert cfg.seq_len > 0\n",
        "    @assert (cfg.dim % cfg.n_heads) == 0\n",
        "    @assert ((cfg.dim ÷ cfg.n_heads) % 2) == 0\n",
        "\n",
        "\n",
        "    d  = Int(cfg.dim); L = Int(cfg.n_layers); V = Int(cfg.vocab_size)\n",
        "    hd = Int(cfg.hidden_dim); T = Int(cfg.seq_len); HS = d ÷ Int(cfg.n_heads); HS2 = HS ÷ 2\n",
        "    @assert w.token_embedding_table.dims == [V, d]\n",
        "    @assert w.rms_att_weight.dims       == [L, d]\n",
        "    for t in (w.wq, w.wk, w.wv, w.wo)\n",
        "        @assert t.dims == [L, d, d]\n",
        "    end\n",
        "    @assert w.rms_ffn_weight.dims       == [L, d]\n",
        "    @assert w.w1.dims                   == [L, hd, d]\n",
        "    @assert w.w2.dims                   == [L, d,  hd]\n",
        "    @assert w.w3.dims                   == [L, hd, d]\n",
        "    @assert w.rms_final_weight.dims     == [d]\n",
        "    @assert w.freq_cis_real.dims        == [T, HS2]\n",
        "    @assert w.freq_cis_imag.dims        == [T, HS2]\n",
        "\n",
        "\n",
        "    header_bytes = 7 * 4\n",
        "    f32_total = expected_f32_count(cfg)\n",
        "    expected_bytes = header_bytes + 4 * f32_total\n",
        "    actual_bytes = filesize(path)\n",
        "    @assert actual_bytes == expected_bytes \"file size mismatch: expected $expected_bytes, got $actual_bytes\"\n",
        "    @assert bytes_consumed == actual_bytes \"did not read to EOF\"\n",
        "\n",
        "    println(\"✓ All tests passed.\")\n",
        "    println(\"Config => dim=$(cfg.dim) hidden_dim=$(cfg.hidden_dim) layers=$(cfg.n_layers) heads=$(cfg.n_heads) kv_heads=$(cfg.n_kv_heads) vocab=$(cfg.vocab_size) seq_len=$(cfg.seq_len)\")\n",
        "    return nothing\n",
        "end\n",
        "\n",
        "\n",
        "const PATH = \"stories15M.bin\"\n",
        "run_selftests(PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kQAK3P4xhhM",
        "outputId": "cefcc674-7ff6-4be0-ec3d-a1888c6be973"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All tests passed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: redefinition of constant Main.HEADER_ORDER. This may fail, cause incorrect answers, or produce other errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config => dim=288 hidden_dim=768 layers=6 heads=6 kv_heads=6 vocab=32000 seq_len=256\n"
          ]
        }
      ]
    }
  ]
}